{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Генерация текста",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-tBeFP38Rp"
      },
      "source": [
        "# **Import библиотек**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=10s\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1Wpkvc3Q2s"
      },
      "source": [
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "import numpy as np # библиотека для работы с массивами данных\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model # из кераса подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input # из кераса загружаем необходимые слои для нейросети\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta # из кераса загружаем выбранный оптимизатор\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # загружаем метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # загружаем токенизатор кераса для обработки текста\n",
        "from tensorflow.keras import utils # загружаем утилиты кераса для one hot кодировки\n",
        "from tensorflow.keras.utils import plot_model # удобный график для визуализации архитектуры модели\n",
        "\n",
        "import yaml # импортируем модуль для удобной работы с файлами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200dSPOYZE7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a90cda5-ad83-41a4-b22a-7726d3508080"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxdi0Fqeg1LH"
      },
      "source": [
        "# **Парсинг данных**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=87s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEA8TR_oerov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e410dd6-8545-4dd0-f190-ba0925d4fc8d"
      },
      "source": [
        "######################\n",
        "# Открываем файл с диалогами\n",
        "######################\n",
        "corpus = open('/content/Диалоги(рассказы).yml', 'r') # открываем файл с диалогами в режиме чтения\n",
        "document = yaml.safe_load(corpus) # загружаем файл *глоссарий\n",
        "conversations = document['разговоры'] # загружаем диалоги из файла и заносим в conversations \n",
        "print('Количество пар вопрос-ответ : {}'.format(len(conversations)))\n",
        "print('Пример диалога : {}'.format(conversations[123]))\n",
        "corpus.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество пар вопрос-ответ : 11905\n",
            "Пример диалога : ['Перезалил?', 'Да вроде бы нет...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYg8z8Vj76bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2cabcb-be88-4a49-ef75-905e8d827896"
      },
      "source": [
        "######################\n",
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "######################\n",
        "# Собираем вопросы и ответы в списки\n",
        "questions = list() # здесь будет список вопросов\n",
        "answers = list() # здесь будет список ответов\n",
        "\n",
        "# В каждом диалоге берем фразу и добавляем в лист\n",
        "# Если в ответе не одна фраза - то сцепляем сколько есть\n",
        "for con in conversations: # для каждой пары вопрос-ответ\n",
        "  if len(con) > 2 : # если ответ содержит более двух предложений (кол-во реплик, кол-во вариантов ответа)\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    replies = con[1:] # а ответную составляем из последующих строк\n",
        "    ans = '' # здесь соберем ответ\n",
        "    for rep in replies: # каждую реплику в ответной реплике\n",
        "      ans += ' ' + rep \n",
        "    answers.append(ans) #добавим в список ответов\n",
        "  elif len(con)> 1: # если на 1 вопрос приходится 1 ответ\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    answers.append(con[1]) # а ответную в список ответов\n",
        "\n",
        "# Очищаем строки с неопределенным типом ответов\n",
        "answersCleaned = list()\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answersCleaned.append(answers[i]) #если тип - строка, то добавляем в ответы\n",
        "  else:\n",
        "    questions.pop(i) # если не строка, то ответ не добавился, и плюс убираем соответствующий вопрос\n",
        "\n",
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = list()\n",
        "for i in range(len(answersCleaned)):\n",
        "  answers.append( '<START> ' + answersCleaned[i] + ' <END>' )\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[200]))\n",
        "print('Ответ : {}'.format(answers[200]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вопрос : Около сотни...\n",
            "Ответ : <START> Точнее! <END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvn1jvRd9tep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd4d515-c573-4d4e-e6d5-7f78d46804f0"
      },
      "source": [
        "######################\n",
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "######################\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))\n",
        "print( 'Размер словаря : {}'.format(vocabularySize))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Фрагмент словаря : [('start', 1), ('end', 2), ('что', 3), ('не', 4), ('я', 5), ('а', 6), ('ты', 7), ('это', 8), ('да', 9), ('в', 10), ('нет', 11), ('как', 12), ('и', 13), ('вы', 14), ('ну', 15), ('с', 16), ('на', 17), ('же', 18), ('так', 19), ('он', 20), ('у', 21), ('кто', 22), ('где', 23), ('все', 24), ('мы', 25), ('то', 26), ('мне', 27), ('тебя', 28), ('меня', 29), ('здесь', 30), ('еще', 31), ('почему', 32), ('о', 33), ('там', 34), ('тебе', 35), ('есть', 36), ('его', 37), ('за', 38), ('куда', 39), ('вот', 40), ('ничего', 41), ('вас', 42), ('знаю', 43), ('чем', 44), ('но', 45), ('она', 46), ('они', 47), ('ли', 48), ('чего', 49), ('вам', 50)]\n",
            "Размер словаря : 15104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsUqzEBXg9Mu"
      },
      "source": [
        "# **Подготовка выборки**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=305s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4nNBJUQgebF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca5e324-f38c-4f13-ec50-76035bb640a4"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы) https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=310s\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = paddedQuestions\n",
        "print('Пример оригинального вопроса на вход : {}'.format(questions[100])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[100])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального вопроса на вход : Какая же мораль?\n",
            "Пример кодированного вопроса на вход : [ 170   18 5709    0    0    0    0    0    0    0    0]\n",
            "Размеры закодированного массива вопросов на вход : (11900, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjvhMuzqFJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9a2c0d-a10e-46db-9935-dbc67b282b60"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы) https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=375s\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = paddedAnswers # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[200])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального ответа на вход: <START> Никакой. Так просто вспомнилось. <END>\n",
            "Пример раскодированного ответа на вход : [   1   86 1189    2    0    0    0    0    0    0    0    0    0]\n",
            "Размеры раскодированного массива ответов на вход : (11900, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwsKk9dzNeqI"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "oneHotAnswers = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRl1k7SVaA6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278382e5-2279-4602-d1a7-f9b92c943875"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[100][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример раскодированного ответа на вход : [    1   673    19    93 10558     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (11900, 13, 15104)\n",
            "Установленная длина вопросов на выход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KR6Mh_hp1f"
      },
      "source": [
        "# **Параметры нейросети и модель обучения**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=915s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRKDr4rhXcZ"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=915s\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yv8Y6QWX2D"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1048s\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYnTen_UWc5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "178bda1e-478d-4470-9eb8-090e8335f844"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1220s\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 200)    3018400     input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 200)    3018400     input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 200), (None, 320800      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  320800      embedding_3[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 15092)  3033492     lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 9,711,892\n",
            "Trainable params: 9,711,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbelEm0zhadD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f243f267-a84c-453f-e322-a08fff97ca66"
      },
      "source": [
        "# Запустим обучение и сохраним модель https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1348s\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=2) \n",
        "#model.save( '/content/drive/My Drive/Предобученные сети/model_100epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "238/238 [==============================] - 38s 129ms/step - loss: 2.4882\n",
            "Epoch 2/2\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 1.9709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83cc247550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEHzJjlRYK5-"
      },
      "source": [
        "model.compile(optimizer=Adadelta(), loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rPD8f5tY4up",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096e75c4-edbd-4409-b645-a9a729a78280"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=2) \n",
        "model.save( '/content/drive/My Drive/Предобученные сети/model_100epochs(rms) + 50(ada).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "238/238 [==============================] - 38s 127ms/step - loss: 4.0082\n",
            "Epoch 2/2\n",
            "238/238 [==============================] - 28s 117ms/step - loss: 4.0044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jrhHhh02_uO"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/Предобученные сети/model_100epochs(rms) + 50(ada).h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_U_rY8UiRL2"
      },
      "source": [
        "# **Подготовка и запуск рабочей нейросети с генерацией ответов**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1428s\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9utvcjh2co"
      },
      "source": [
        "######################\n",
        "# Создаем рабочую модель для вывода ответов на запросы пользователя https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1455s\n",
        "######################\n",
        "def makeInferenceModels():\n",
        "  # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSOhZpgh9LI"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1593s\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = list() # здесь будет последовательность токенов/индексов\n",
        "  for word in words: # для каждого слова в предложении\n",
        "    tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e60230-c6f3-4063-c1ff-6b0d8d7cfc96"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем модель https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1645s\n",
        "######################\n",
        "\n",
        "encModel , decModel = makeInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(3): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : привет\n",
            " что тебе надо человек \n",
            "Задайте вопрос : зачем ты здесь\n",
            " я хотела посмотреть на посмотреть на что я два \n",
            "Задайте вопрос : сколько тебе лет\n",
            " не знаю а сколько нужно \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfhu067toXGQ"
      },
      "source": [
        "# **Загрузка и запуск предобученной модели**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2100s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Lg3eOVqKyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eaac349-74a4-4258-f28a-338374f5b1d1"
      },
      "source": [
        "# Подгружаем модель из файла и выведем её параметры\n",
        "model = load_model('/content/drive/MyDrive/Базы/model_chatbot_100epochs(rms)+50(ada).h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 200)    3020800     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 200)    3020800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 200), (None, 320800      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 200),  320800      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 15104)  3035904     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 9,719,104\n",
            "Trainable params: 9,719,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEfb58cXqsKi"
      },
      "source": [
        "######################\n",
        "# Устанавливаем связи между слоями рабочей модели и предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2174s\n",
        "######################\n",
        "def loadInferenceModels():\n",
        "  encoderInputs = model.input[0]   # входом энкодера рабочей модели будет первый инпут предобученной модели(input_1)\n",
        "  encoderEmbedding = model.layers[2] # связываем эмбединг слои(model.layers[2] это embedding_1)\n",
        "  encoderOutputs, state_h_enc, state_c_enc = model.layers[4].output # вытягиваем аутпуты из первого LSTM слоя обуч.модели и даем энкодеру(lstm_1)\n",
        "  encoderStates = [state_h_enc, state_c_enc] # ложим забранные состояния в состояния энкодера\n",
        "  encoderModel = Model(encoderInputs, encoderStates) # формируем модель\n",
        "\n",
        "  decoderInputs = model.input[1]   # входом декодера рабочей модели будет второй инпут предобученной модели(input_2)\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  decoderEmbedding = model.layers[3] # связываем эмбединг слои(model.layers[3] это embedding_2)\n",
        "  decoderLSTM = model.layers[5] # связываем LSTM слои(model.layers[5] это lstm_2)\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding.output, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "\n",
        "  decoderDense = model.layers[6] # связываем полносвязные слои(model.layers[6] это dense_1)\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # выход с LSTM мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "    # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "    # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTpsqjakx2rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38673a26-2f21-4464-c342-21925076c92b"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2272s\n",
        "######################\n",
        "\n",
        "encModel , decModel = loadInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : привет\n",
            " с господин это не \n",
            "Задайте вопрос : как дела\n",
            " за ночь сделали вставай мотор \n",
            "Задайте вопрос : кто ты\n",
            " ты ник меня отец \n",
            "Задайте вопрос : сколько тебе лет\n",
            " двадцать ваше \n",
            "Задайте вопрос : кто твой отец\n",
            " да я не \n",
            "Задайте вопрос : когда домой\n",
            " сейчас очень просто что же \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98O0XcM9yCbm"
      },
      "source": [
        "# **Глоссарий**\n",
        "-  Seq2Seq - sequence-to-sequence модель, состоит из двух рекуррентных нейронных сетей (RNN): \n",
        "\n",
        "encoder (кодер), которая обрабатывает входные данные,\n",
        "\n",
        "decoder (декодер), которая генерирует данные вывода.\n",
        "- Yaml - удобный текстовый формат, позволяющий хранить структурированные данные в иерархии. https://ru.bmstu.wiki/YAML\n",
        "yaml.safe_load - безопасный метод загрузки данных из файлов, предотвращающий возможность запуска произвольного кода для файлов из ненадежных источников\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqJ3CgG6jJMq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}